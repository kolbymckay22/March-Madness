{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import gpboost as gpb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.3.10).\n",
      "Path to dataset files: /Users/kolbytaylor/.cache/kagglehub/datasets/nishaanamin/march-madness-data/versions/104\n"
     ]
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"nishaanamin/march-madness-data\")\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading all the different data sets in\n",
    "\n",
    "# Tournament Results and Data\n",
    "coach_results = pd.read_csv(\"march-madness-data/versions/83/Coach Results.csv\")\n",
    "seed_results = pd.read_csv(\"march-madness-data/versions/83/Seed Results.csv\")\n",
    "team_results = pd.read_csv(\"march-madness-data/versions/83/Team Results.csv\")\n",
    "conference_results = pd.read_csv(\"march-madness-data/versions/83/Conference Results.csv\")\n",
    "tournament_locations = pd.read_csv(\"march-madness-data/versions/83/Tournament Locations.csv\")\n",
    "tournament_matchups = pd.read_csv(\"march-madness-data/versions/83/Tournament Matchups.csv\")\n",
    "upset_counts = pd.read_csv(\"march-madness-data/versions/83/Upset Count.csv\")\n",
    "upset_seed_info = pd.read_csv(\"march-madness-data/versions/83/Upset Seed Info.csv\")\n",
    "\n",
    "# Bartorvik\n",
    "barttorvik_away_neutral = pd.read_csv(\"march-madness-data/versions/83/Barttorvik Away-Neutral.csv\")\n",
    "barttorvik_away = pd.read_csv(\"march-madness-data/versions/83/Barttorvik Away.csv\")\n",
    "barttorvik_home = pd.read_csv(\"march-madness-data/versions/83/Barttorvik Home.csv\")\n",
    "barttorvik_neutral = pd.read_csv(\"march-madness-data/versions/83/Barttorvik Home.csv\")\n",
    "kenpom_barttorvik = pd.read_csv(\"march-madness-data/versions/83/KenPom Barttorvik.csv\")\n",
    "\n",
    "# Conference Stats\n",
    "conference_stats = pd.read_csv(\"march-madness-data/versions/83/Conference Stats.csv\")\n",
    "conference_away_neutral = pd.read_csv(\"march-madness-data/versions/83/Conference Stats Away Neutral.csv\")\n",
    "conference_away = pd.read_csv(\"march-madness-data/versions/83/Conference Stats Away.csv\")\n",
    "conference_home = pd.read_csv(\"march-madness-data/versions/83/Conference Stats Home.csv\")\n",
    "conference_neutral = pd.read_csv(\"march-madness-data/versions/83/Conference Stats Neutral.csv\")\n",
    "\n",
    "# Resumes\n",
    "resumes = pd.read_csv(\"march-madness-data/versions/83/Resumes.csv\")\n",
    "\n",
    "# Shooting Splits\n",
    "shooting_splits = pd.read_csv(\"march-madness-data/versions/83/Shooting Splits.csv\")\n",
    "\n",
    "# Other Websites\n",
    "ratings_538 = pd.read_csv(\"march-madness-data/versions/83/538 Ratings.csv\")\n",
    "heat_check = pd.read_csv(\"march-madness-data/versions/83/Heat Check Tournament Index.csv\")\n",
    "\n",
    "# People's Opinions\n",
    "preseason_votes = pd.read_csv(\"march-madness-data/versions/83/Preseason Votes.csv\")\n",
    "public_picks = pd.read_csv(\"march-madness-data/versions/83/Public Picks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the columns in the dataframes that have home, away, and neutral; and subscript them so that we can recognize what it is\n",
    "# Barttorvik\n",
    "for col in barttorvik_away_neutral.columns:\n",
    "    barttorvik_away_neutral = barttorvik_away_neutral.rename(columns={col: col + \" AWAY-NEUTRAL\"})\n",
    "\n",
    "for col in barttorvik_away.columns:\n",
    "    barttorvik_away = barttorvik_away.rename(columns={col: col + \" AWAY\"})\n",
    "\n",
    "for col in barttorvik_home.columns:\n",
    "    barttorvik_home = barttorvik_home.rename(columns={col: col + \" HOME\"})\n",
    "\n",
    "for col in barttorvik_neutral.columns:\n",
    "    barttorvik_neutral = barttorvik_neutral.rename(columns={col: col + \" NEUTRAL\"})\n",
    "\n",
    "\n",
    "\n",
    "# Conference Statistics\n",
    "for col in conference_away_neutral.columns:\n",
    "    conference_away_neutral = conference_away_neutral.rename(columns={col: col + \" AWAY-NEUTRAL\"})\n",
    "\n",
    "for col in conference_away.columns:\n",
    "    conference_away = conference_away.rename(columns={col: col + \" AWAY\"})\n",
    "\n",
    "for col in conference_home.columns:\n",
    "    conference_home = conference_home.rename(columns={col: col + \" HOME\"})\n",
    "\n",
    "for col in conference_neutral.columns:\n",
    "    conference_neutral = conference_neutral.rename(columns={col: col + \" NEUTRAL\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR AWAY-NEUTRAL</th>\n",
       "      <th>TEAM NO AWAY-NEUTRAL</th>\n",
       "      <th>TEAM ID AWAY-NEUTRAL</th>\n",
       "      <th>TEAM AWAY-NEUTRAL</th>\n",
       "      <th>SEED AWAY-NEUTRAL</th>\n",
       "      <th>ROUND AWAY-NEUTRAL</th>\n",
       "      <th>BADJ EM AWAY-NEUTRAL</th>\n",
       "      <th>BADJ O AWAY-NEUTRAL</th>\n",
       "      <th>BADJ D AWAY-NEUTRAL</th>\n",
       "      <th>BARTHAG AWAY-NEUTRAL</th>\n",
       "      <th>...</th>\n",
       "      <th>BADJT RANK AWAY-NEUTRAL</th>\n",
       "      <th>AVG HGT RANK AWAY-NEUTRAL</th>\n",
       "      <th>EFF HGT RANK AWAY-NEUTRAL</th>\n",
       "      <th>EXP RANK AWAY-NEUTRAL</th>\n",
       "      <th>TALENT RANK AWAY-NEUTRAL</th>\n",
       "      <th>FT% RANK AWAY-NEUTRAL</th>\n",
       "      <th>OP FT% RANK AWAY-NEUTRAL</th>\n",
       "      <th>PPPO RANK AWAY-NEUTRAL</th>\n",
       "      <th>PPPD RANK AWAY-NEUTRAL</th>\n",
       "      <th>ELITE SOS RANK AWAY-NEUTRAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>1079</td>\n",
       "      <td>197</td>\n",
       "      <td>Akron</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>105.0</td>\n",
       "      <td>101.9</td>\n",
       "      <td>0.585</td>\n",
       "      <td>...</td>\n",
       "      <td>265</td>\n",
       "      <td>238</td>\n",
       "      <td>199</td>\n",
       "      <td>19</td>\n",
       "      <td>176</td>\n",
       "      <td>186</td>\n",
       "      <td>188</td>\n",
       "      <td>120</td>\n",
       "      <td>47</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>1078</td>\n",
       "      <td>48</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>125.4</td>\n",
       "      <td>106.7</td>\n",
       "      <td>0.865</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>156</td>\n",
       "      <td>106</td>\n",
       "      <td>12</td>\n",
       "      <td>357</td>\n",
       "      <td>3</td>\n",
       "      <td>351</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>1077</td>\n",
       "      <td>33</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23.7</td>\n",
       "      <td>119.7</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.927</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>37</td>\n",
       "      <td>196</td>\n",
       "      <td>7</td>\n",
       "      <td>157</td>\n",
       "      <td>284</td>\n",
       "      <td>19</td>\n",
       "      <td>98</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>1076</td>\n",
       "      <td>43</td>\n",
       "      <td>Auburn</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>26.8</td>\n",
       "      <td>120.8</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.947</td>\n",
       "      <td>...</td>\n",
       "      <td>67</td>\n",
       "      <td>86</td>\n",
       "      <td>76</td>\n",
       "      <td>127</td>\n",
       "      <td>69</td>\n",
       "      <td>127</td>\n",
       "      <td>260</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>1075</td>\n",
       "      <td>36</td>\n",
       "      <td>Baylor</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>17.6</td>\n",
       "      <td>117.7</td>\n",
       "      <td>100.1</td>\n",
       "      <td>0.866</td>\n",
       "      <td>...</td>\n",
       "      <td>275</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>304</td>\n",
       "      <td>34</td>\n",
       "      <td>137</td>\n",
       "      <td>248</td>\n",
       "      <td>52</td>\n",
       "      <td>189</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR AWAY-NEUTRAL  TEAM NO AWAY-NEUTRAL  TEAM ID AWAY-NEUTRAL  \\\n",
       "0               2024                  1079                   197   \n",
       "1               2024                  1078                    48   \n",
       "2               2024                  1077                    33   \n",
       "3               2024                  1076                    43   \n",
       "4               2024                  1075                    36   \n",
       "\n",
       "  TEAM AWAY-NEUTRAL  SEED AWAY-NEUTRAL  ROUND AWAY-NEUTRAL  \\\n",
       "0             Akron                 14                   0   \n",
       "1           Alabama                  4                   0   \n",
       "2           Arizona                  2                   0   \n",
       "3            Auburn                  4                   0   \n",
       "4            Baylor                  3                   0   \n",
       "\n",
       "   BADJ EM AWAY-NEUTRAL  BADJ O AWAY-NEUTRAL  BADJ D AWAY-NEUTRAL  \\\n",
       "0                   3.1                105.0                101.9   \n",
       "1                  18.7                125.4                106.7   \n",
       "2                  23.7                119.7                 96.0   \n",
       "3                  26.8                120.8                 94.0   \n",
       "4                  17.6                117.7                100.1   \n",
       "\n",
       "   BARTHAG AWAY-NEUTRAL  ...  BADJT RANK AWAY-NEUTRAL  \\\n",
       "0                 0.585  ...                      265   \n",
       "1                 0.865  ...                       10   \n",
       "2                 0.927  ...                       40   \n",
       "3                 0.947  ...                       67   \n",
       "4                 0.866  ...                      275   \n",
       "\n",
       "   AVG HGT RANK AWAY-NEUTRAL  EFF HGT RANK AWAY-NEUTRAL  \\\n",
       "0                        238                        199   \n",
       "1                         33                          8   \n",
       "2                         50                         37   \n",
       "3                         86                         76   \n",
       "4                         31                         22   \n",
       "\n",
       "   EXP RANK AWAY-NEUTRAL  TALENT RANK AWAY-NEUTRAL  FT% RANK AWAY-NEUTRAL  \\\n",
       "0                     19                       176                    186   \n",
       "1                    156                       106                     12   \n",
       "2                    196                         7                    157   \n",
       "3                    127                        69                    127   \n",
       "4                    304                        34                    137   \n",
       "\n",
       "   OP FT% RANK AWAY-NEUTRAL  PPPO RANK AWAY-NEUTRAL  PPPD RANK AWAY-NEUTRAL  \\\n",
       "0                       188                     120                      47   \n",
       "1                       357                       3                     351   \n",
       "2                       284                      19                      98   \n",
       "3                       260                       5                      18   \n",
       "4                       248                      52                     189   \n",
       "\n",
       "   ELITE SOS RANK AWAY-NEUTRAL  \n",
       "0                          269  \n",
       "1                            8  \n",
       "2                           52  \n",
       "3                           77  \n",
       "4                           11  \n",
       "\n",
       "[5 rows x 85 columns]"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "barttorvik_away_neutral.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many columns in the Barttorvik data, and splitting them out by where the team played multiplies it by five. In total we have around 170 features. Half of them are metrics and the other half rank those metrics in all Division 1. We should probably sort these out first. I'm going to try doing some analysis with the features. I'm going to fit the same model with the overall, away, netural, home, and neutral-away features and see which ones work the best, as well as do some AB testing to see if there's a significant difference between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the target, 0-6 based on how many games were won\n",
    "conditions = [\n",
    "    (kenpom_barttorvik['ROUND'] == 0) | (kenpom_barttorvik['ROUND'] == 68),\n",
    "    (kenpom_barttorvik['ROUND'] == 64),\n",
    "    (kenpom_barttorvik['ROUND'] == 32),\n",
    "    (kenpom_barttorvik['ROUND'] == 16),\n",
    "    (kenpom_barttorvik['ROUND'] == 8),\n",
    "    (kenpom_barttorvik['ROUND'] == 4),\n",
    "    (kenpom_barttorvik['ROUND'] == 2),\n",
    "    (kenpom_barttorvik['ROUND'] == 1)\n",
    "]\n",
    "\n",
    "values = [np.nan, 0, 1, 2, 3, 4, 5, 6]\n",
    "\n",
    "kenpom_barttorvik['TARGET'] = np.select(conditions, values, default=np.nan)\n",
    "barttorvik_away_neutral['TARGET'] = np.select(conditions, values, default=np.nan)\n",
    "barttorvik_away['TARGET'] = np.select(conditions, values, default=np.nan)\n",
    "barttorvik_home['TARGET'] = np.select(conditions, values, default=np.nan)\n",
    "barttorvik_neutral['TARGET'] = np.select(conditions, values, default=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR AWAY-NEUTRAL</th>\n",
       "      <th>TEAM NO AWAY-NEUTRAL</th>\n",
       "      <th>TEAM ID AWAY-NEUTRAL</th>\n",
       "      <th>TEAM AWAY-NEUTRAL</th>\n",
       "      <th>SEED AWAY-NEUTRAL</th>\n",
       "      <th>ROUND AWAY-NEUTRAL</th>\n",
       "      <th>BADJ EM AWAY-NEUTRAL</th>\n",
       "      <th>BADJ O AWAY-NEUTRAL</th>\n",
       "      <th>BADJ D AWAY-NEUTRAL</th>\n",
       "      <th>BARTHAG AWAY-NEUTRAL</th>\n",
       "      <th>...</th>\n",
       "      <th>AVG HGT RANK AWAY-NEUTRAL</th>\n",
       "      <th>EFF HGT RANK AWAY-NEUTRAL</th>\n",
       "      <th>EXP RANK AWAY-NEUTRAL</th>\n",
       "      <th>TALENT RANK AWAY-NEUTRAL</th>\n",
       "      <th>FT% RANK AWAY-NEUTRAL</th>\n",
       "      <th>OP FT% RANK AWAY-NEUTRAL</th>\n",
       "      <th>PPPO RANK AWAY-NEUTRAL</th>\n",
       "      <th>PPPD RANK AWAY-NEUTRAL</th>\n",
       "      <th>ELITE SOS RANK AWAY-NEUTRAL</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>1079</td>\n",
       "      <td>197</td>\n",
       "      <td>Akron</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>105.0</td>\n",
       "      <td>101.9</td>\n",
       "      <td>0.585</td>\n",
       "      <td>...</td>\n",
       "      <td>238</td>\n",
       "      <td>199</td>\n",
       "      <td>19</td>\n",
       "      <td>176</td>\n",
       "      <td>186</td>\n",
       "      <td>188</td>\n",
       "      <td>120</td>\n",
       "      <td>47</td>\n",
       "      <td>269</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>1078</td>\n",
       "      <td>48</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>125.4</td>\n",
       "      <td>106.7</td>\n",
       "      <td>0.865</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>156</td>\n",
       "      <td>106</td>\n",
       "      <td>12</td>\n",
       "      <td>357</td>\n",
       "      <td>3</td>\n",
       "      <td>351</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>1077</td>\n",
       "      <td>33</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23.7</td>\n",
       "      <td>119.7</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.927</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>37</td>\n",
       "      <td>196</td>\n",
       "      <td>7</td>\n",
       "      <td>157</td>\n",
       "      <td>284</td>\n",
       "      <td>19</td>\n",
       "      <td>98</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>1076</td>\n",
       "      <td>43</td>\n",
       "      <td>Auburn</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>26.8</td>\n",
       "      <td>120.8</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.947</td>\n",
       "      <td>...</td>\n",
       "      <td>86</td>\n",
       "      <td>76</td>\n",
       "      <td>127</td>\n",
       "      <td>69</td>\n",
       "      <td>127</td>\n",
       "      <td>260</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>77</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>1075</td>\n",
       "      <td>36</td>\n",
       "      <td>Baylor</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>17.6</td>\n",
       "      <td>117.7</td>\n",
       "      <td>100.1</td>\n",
       "      <td>0.866</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>304</td>\n",
       "      <td>34</td>\n",
       "      <td>137</td>\n",
       "      <td>248</td>\n",
       "      <td>52</td>\n",
       "      <td>189</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR AWAY-NEUTRAL  TEAM NO AWAY-NEUTRAL  TEAM ID AWAY-NEUTRAL  \\\n",
       "0               2024                  1079                   197   \n",
       "1               2024                  1078                    48   \n",
       "2               2024                  1077                    33   \n",
       "3               2024                  1076                    43   \n",
       "4               2024                  1075                    36   \n",
       "\n",
       "  TEAM AWAY-NEUTRAL  SEED AWAY-NEUTRAL  ROUND AWAY-NEUTRAL  \\\n",
       "0             Akron                 14                   0   \n",
       "1           Alabama                  4                   0   \n",
       "2           Arizona                  2                   0   \n",
       "3            Auburn                  4                   0   \n",
       "4            Baylor                  3                   0   \n",
       "\n",
       "   BADJ EM AWAY-NEUTRAL  BADJ O AWAY-NEUTRAL  BADJ D AWAY-NEUTRAL  \\\n",
       "0                   3.1                105.0                101.9   \n",
       "1                  18.7                125.4                106.7   \n",
       "2                  23.7                119.7                 96.0   \n",
       "3                  26.8                120.8                 94.0   \n",
       "4                  17.6                117.7                100.1   \n",
       "\n",
       "   BARTHAG AWAY-NEUTRAL  ...  AVG HGT RANK AWAY-NEUTRAL  \\\n",
       "0                 0.585  ...                        238   \n",
       "1                 0.865  ...                         33   \n",
       "2                 0.927  ...                         50   \n",
       "3                 0.947  ...                         86   \n",
       "4                 0.866  ...                         31   \n",
       "\n",
       "   EFF HGT RANK AWAY-NEUTRAL  EXP RANK AWAY-NEUTRAL  TALENT RANK AWAY-NEUTRAL  \\\n",
       "0                        199                     19                       176   \n",
       "1                          8                    156                       106   \n",
       "2                         37                    196                         7   \n",
       "3                         76                    127                        69   \n",
       "4                         22                    304                        34   \n",
       "\n",
       "   FT% RANK AWAY-NEUTRAL  OP FT% RANK AWAY-NEUTRAL  PPPO RANK AWAY-NEUTRAL  \\\n",
       "0                    186                       188                     120   \n",
       "1                     12                       357                       3   \n",
       "2                    157                       284                      19   \n",
       "3                    127                       260                       5   \n",
       "4                    137                       248                      52   \n",
       "\n",
       "   PPPD RANK AWAY-NEUTRAL  ELITE SOS RANK AWAY-NEUTRAL  TARGET  \n",
       "0                      47                          269     NaN  \n",
       "1                     351                            8     NaN  \n",
       "2                      98                           52     NaN  \n",
       "3                      18                           77     NaN  \n",
       "4                     189                           11     NaN  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "barttorvik_away_neutral.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_barttorvik = kenpom_barttorvik.drop(columns=['YEAR', 'CONF', 'CONF ID', 'QUAD NO', 'QUAD ID', 'TEAM NO', 'TEAM ID', 'TEAM', 'SEED', 'ROUND', 'TARGET'])\n",
    "y_barttorvik = kenpom_barttorvik['TARGET']\n",
    "\n",
    "X_barttorvik_away_neutral = barttorvik_away_neutral.drop(columns=['YEAR AWAY-NEUTRAL', 'TEAM NO AWAY-NEUTRAL', 'TEAM ID AWAY-NEUTRAL', 'TEAM AWAY-NEUTRAL', 'SEED AWAY-NEUTRAL', 'ROUND AWAY-NEUTRAL', 'TARGET'])\n",
    "y_barttorvik_away_neutral = barttorvik_away_neutral['TARGET']\n",
    "\n",
    "X_barttorvik_away = barttorvik_away.drop(columns=['YEAR AWAY', 'TEAM NO AWAY', 'TEAM ID AWAY', 'TEAM AWAY', 'SEED AWAY', 'ROUND AWAY', 'TARGET'])\n",
    "y_barttorvik_away = barttorvik_away['TARGET']\n",
    "\n",
    "X_barttorvik_home = barttorvik_home.drop(columns=['YEAR HOME', 'TEAM NO HOME', 'TEAM ID HOME', 'TEAM HOME', 'SEED HOME', 'ROUND HOME', 'TARGET'])\n",
    "y_barttorvik_home = barttorvik_home['TARGET']\n",
    "\n",
    "X_barttorvik_neutral = barttorvik_neutral.drop(columns=['YEAR NEUTRAL', 'TEAM NO NEUTRAL', 'TEAM ID NEUTRAL', 'TEAM NEUTRAL', 'SEED NEUTRAL', 'ROUND NEUTRAL', 'TARGET'])\n",
    "y_barttorvik_neutral = barttorvik_neutral['TARGET']\n",
    "\n",
    "# Drop rows where TARGET is null\n",
    "X_barttorvik = X_barttorvik.loc[y_barttorvik.notna()]\n",
    "y_barttorvik = y_barttorvik.dropna()\n",
    "\n",
    "X_barttorvik_away_neutral = X_barttorvik_away_neutral.loc[y_barttorvik_away_neutral.notna()]\n",
    "y_barttorvik_away_neutral = y_barttorvik_away_neutral.dropna()\n",
    "\n",
    "X_barttorvik_away = X_barttorvik_away.loc[y_barttorvik_away.notna()]\n",
    "y_barttorvik_away = y_barttorvik_away.dropna()\n",
    "\n",
    "X_barttorvik_home = X_barttorvik_home.loc[y_barttorvik_home.notna()]\n",
    "y_barttorvik_home = y_barttorvik_home.dropna()\n",
    "\n",
    "X_barttorvik_neutral = X_barttorvik_neutral.loc[y_barttorvik_neutral.notna()]\n",
    "y_barttorvik_neutral = y_barttorvik_neutral.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't want to have to do feature scaling or do anything with assumptions because this is just EDA modeling, so I'm going to use XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# No null values! That's nice. \n",
    "print(X_barttorvik.isnull().sum()[X_barttorvik.isnull().sum() > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K TEMPO           float64\n",
      "K TEMPO RANK        int64\n",
      "KADJ T            float64\n",
      "KADJ T RANK         int64\n",
      "K OFF             float64\n",
      "                   ...   \n",
      "FT% RANK            int64\n",
      "OP FT% RANK         int64\n",
      "PPPO RANK           int64\n",
      "PPPD RANK           int64\n",
      "ELITE SOS RANK      int64\n",
      "Length: 93, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Datatypes look good\n",
    "print(X_barttorvik.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-rmse:1.24614\n",
      "[10]\teval-rmse:1.07732\n",
      "[20]\teval-rmse:1.08317\n",
      "[30]\teval-rmse:1.08900\n",
      "[33]\teval-rmse:1.09478\n",
      "Best iteration: 14\n",
      "Test RMSE: 1.0766\n"
     ]
    }
   ],
   "source": [
    "# Train-test split (80-20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_barttorvik, y_barttorvik, test_size=0.2, random_state=42)\n",
    "\n",
    "# Prepare DMatrix (required for xgb.train)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Define hyperparameters grid manually\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'max_depth': 2,\n",
    "    'learning_rate': 0.2,\n",
    "    'subsample': 0.6,\n",
    "    'alpha': 10,\n",
    "    'colsample_bytree': 0.6,\n",
    "    'random_state': 42,\n",
    "    'min_child_weight': 5\n",
    "}\n",
    "\n",
    "# Set up training with early stopping\n",
    "evallist = [(dtest, 'eval')]\n",
    "\n",
    "# Train the model with early stopping\n",
    "bst = xgb.train(\n",
    "    params, \n",
    "    dtrain, \n",
    "    num_boost_round=1000,\n",
    "    evals=evallist, \n",
    "    early_stopping_rounds=20,\n",
    "    verbose_eval=10\n",
    ")\n",
    "\n",
    "# Get the best iteration from early stopping\n",
    "best_iteration = bst.best_iteration\n",
    "print(f\"Best iteration: {best_iteration}\")\n",
    "\n",
    "# Make predictions using the best iteration\n",
    "y_pred = bst.predict(dtest, iteration_range=(0, best_iteration))\n",
    "\n",
    "# Calculate RMSE on test set\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Print the result\n",
    "print(f\"Test RMSE: {test_rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-rmse:1.24819\n",
      "[10]\teval-rmse:1.08775\n",
      "[20]\teval-rmse:1.08954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30]\teval-rmse:1.09811\n",
      "[33]\teval-rmse:1.10664\n",
      "Best iteration: 13\n",
      "Test RMSE: 1.0897\n"
     ]
    }
   ],
   "source": [
    "# Train-test split (80-20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_barttorvik_away_neutral, y_barttorvik_away_neutral, test_size=0.2, random_state=42)\n",
    "\n",
    "# Prepare DMatrix (required for xgb.train)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Define hyperparameters grid manually\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'max_depth': 2,\n",
    "    'learning_rate': 0.2,\n",
    "    'subsample': 0.6,\n",
    "    'alpha': 10,\n",
    "    'colsample_bytree': 0.6,\n",
    "    'random_state': 42,\n",
    "    'min_child_weight': 5\n",
    "}\n",
    "\n",
    "# Set up training with early stopping\n",
    "evallist = [(dtest, 'eval')]\n",
    "\n",
    "# Train the model with early stopping\n",
    "bst = xgb.train(\n",
    "    params, \n",
    "    dtrain, \n",
    "    num_boost_round=1000,\n",
    "    evals=evallist, \n",
    "    early_stopping_rounds=20,\n",
    "    verbose_eval=10\n",
    ")\n",
    "\n",
    "# Get the best iteration from early stopping\n",
    "best_iteration = bst.best_iteration\n",
    "print(f\"Best iteration: {best_iteration}\")\n",
    "\n",
    "# Make predictions using the best iteration\n",
    "y_pred = bst.predict(dtest, iteration_range=(0, best_iteration))\n",
    "\n",
    "# Calculate RMSE on test set\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Print the result\n",
    "print(f\"Test RMSE: {test_rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-rmse:1.24884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\teval-rmse:1.12063\n",
      "[20]\teval-rmse:1.11433\n",
      "[30]\teval-rmse:1.12300\n",
      "[33]\teval-rmse:1.13158\n",
      "Best iteration: 14\n",
      "Test RMSE: 1.1112\n"
     ]
    }
   ],
   "source": [
    "# Train-test split (80-20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_barttorvik_away, y_barttorvik_away, test_size=0.2, random_state=42)\n",
    "\n",
    "# Prepare DMatrix (required for xgb.train)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Define hyperparameters grid manually\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'max_depth': 2,\n",
    "    'learning_rate': 0.2,\n",
    "    'subsample': 0.6,\n",
    "    'alpha': 10,\n",
    "    'colsample_bytree': 0.6,\n",
    "    'random_state': 42,\n",
    "    'min_child_weight': 5\n",
    "}\n",
    "\n",
    "# Set up training with early stopping\n",
    "evallist = [(dtest, 'eval')]\n",
    "\n",
    "# Train the model with early stopping\n",
    "bst = xgb.train(\n",
    "    params, \n",
    "    dtrain, \n",
    "    num_boost_round=1000,\n",
    "    evals=evallist, \n",
    "    early_stopping_rounds=20,\n",
    "    verbose_eval=10\n",
    ")\n",
    "\n",
    "# Get the best iteration from early stopping\n",
    "best_iteration = bst.best_iteration\n",
    "print(f\"Best iteration: {best_iteration}\")\n",
    "\n",
    "# Make predictions using the best iteration\n",
    "y_pred = bst.predict(dtest, iteration_range=(0, best_iteration))\n",
    "\n",
    "# Calculate RMSE on test set\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Print the result\n",
    "print(f\"Test RMSE: {test_rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-rmse:1.24086\n",
      "[10]\teval-rmse:1.07804\n",
      "[20]\teval-rmse:1.08300\n",
      "[30]\teval-rmse:1.09856\n",
      "Best iteration: 10\n",
      "Test RMSE: 1.0840\n"
     ]
    }
   ],
   "source": [
    "# Train-test split (80-20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_barttorvik_home, y_barttorvik_home, test_size=0.2, random_state=42)\n",
    "\n",
    "# Prepare DMatrix (required for xgb.train)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Define hyperparameters grid manually\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'max_depth': 2,\n",
    "    'learning_rate': 0.2,\n",
    "    'subsample': 0.6,\n",
    "    'alpha': 10,\n",
    "    'colsample_bytree': 0.6,\n",
    "    'random_state': 42,\n",
    "    'min_child_weight': 5\n",
    "}\n",
    "\n",
    "# Set up training with early stopping\n",
    "evallist = [(dtest, 'eval')]\n",
    "\n",
    "# Train the model with early stopping\n",
    "bst = xgb.train(\n",
    "    params, \n",
    "    dtrain, \n",
    "    num_boost_round=1000,\n",
    "    evals=evallist, \n",
    "    early_stopping_rounds=20,\n",
    "    verbose_eval=10\n",
    ")\n",
    "\n",
    "# Get the best iteration from early stopping\n",
    "best_iteration = bst.best_iteration\n",
    "print(f\"Best iteration: {best_iteration}\")\n",
    "\n",
    "# Make predictions using the best iteration\n",
    "y_pred = bst.predict(dtest, iteration_range=(0, best_iteration))\n",
    "\n",
    "# Calculate RMSE on test set\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Print the result\n",
    "print(f\"Test RMSE: {test_rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-rmse:1.24086\n",
      "[10]\teval-rmse:1.07804\n",
      "[20]\teval-rmse:1.08300\n",
      "[30]\teval-rmse:1.09856\n",
      "Best iteration: 10\n",
      "Test RMSE: 1.0840\n"
     ]
    }
   ],
   "source": [
    "# Train-test split (80-20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_barttorvik_neutral, y_barttorvik_neutral, test_size=0.2, random_state=42)\n",
    "\n",
    "# Prepare DMatrix (required for xgb.train)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Define hyperparameters grid manually\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'max_depth': 2,\n",
    "    'learning_rate': 0.2,\n",
    "    'subsample': 0.6,\n",
    "    'alpha': 10,\n",
    "    'colsample_bytree': 0.6,\n",
    "    'random_state': 42,\n",
    "    'min_child_weight': 5\n",
    "}\n",
    "\n",
    "# Set up training with early stopping\n",
    "evallist = [(dtest, 'eval')]\n",
    "\n",
    "# Train the model with early stopping\n",
    "bst = xgb.train(\n",
    "    params, \n",
    "    dtrain, \n",
    "    num_boost_round=1000,\n",
    "    evals=evallist, \n",
    "    early_stopping_rounds=20,\n",
    "    verbose_eval=10\n",
    ")\n",
    "\n",
    "# Get the best iteration from early stopping\n",
    "best_iteration = bst.best_iteration\n",
    "print(f\"Best iteration: {best_iteration}\")\n",
    "\n",
    "# Make predictions using the best iteration\n",
    "y_pred = bst.predict(dtest, iteration_range=(0, best_iteration))\n",
    "\n",
    "# Calculate RMSE on test set\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Print the result\n",
    "print(f\"Test RMSE: {test_rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Results:\n",
    "\n",
    "The results were consistent across all models. The hyperparameters selected by each model were identical:\n",
    "\n",
    "- subsample: 0.6  \n",
    "- min_child_weight: 5  \n",
    "- max_depth: 2  \n",
    "- learning_rate: 0.05  \n",
    "- lambda: 5  \n",
    "- colsample_bytree: 1.0  \n",
    "- alpha: 10  \n",
    "\n",
    "---\n",
    "\n",
    "### RMSE:\n",
    "\n",
    "- Overall: 1.07  \n",
    "- Away-Neutral: 1.08  \n",
    "- Away: 1.11  \n",
    "- Home: 1.08  \n",
    "- Neutral: 1.08  \n",
    "\n",
    "---\n",
    "\n",
    "The Overall RMSE might be slightly better due to the inclusion of a few different features. Based on this analysis, we have decided to use the overall Barttorvik data in our analysis moving forward.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting with the Kenpom data\n",
    "all_data = kenpom_barttorvik\n",
    "\n",
    "# Add 538 Ratings\n",
    "all_data = all_data.merge(ratings_538, how='left', on='TEAM NO')\n",
    "all_data = all_data.drop(columns=['YEAR_y', 'TEAM_y', 'SEED_y', 'ROUND_y'])\n",
    "all_data = all_data.rename(columns={'YEAR_x': 'YEAR', 'TEAM_x': 'TEAM', 'SEED_x': 'SEED', 'ROUND_x': 'ROUND'})\n",
    "\n",
    "# Add Heat Check metrics\n",
    "all_data = all_data.merge(heat_check, how='left', on='TEAM NO')\n",
    "all_data = all_data.drop(columns=['YEAR_y', 'TEAM_y', 'SEED_y', 'ROUND_y'])\n",
    "all_data = all_data.rename(columns={'YEAR_x': 'YEAR', 'TEAM_x': 'TEAM', 'SEED_x': 'SEED', 'ROUND_x': 'ROUND'})\n",
    "\n",
    "# Add resume data, includes strength of schedule\n",
    "all_data = all_data.merge(resumes, how='left', on='TEAM NO')\n",
    "all_data = all_data.drop(columns=['YEAR_y', 'TEAM_y'])\n",
    "all_data = all_data.rename(columns={'YEAR_x': 'YEAR', 'TEAM_x': 'TEAM', 'SEED_x': 'SEED', 'ROUND_x': 'ROUND'})\n",
    "\n",
    "# Shooting splits of each team\n",
    "all_data = all_data.merge(shooting_splits, how='left', on='TEAM NO')\n",
    "all_data = all_data.drop(columns=['YEAR_y', 'TEAM_y', 'SEED_y', 'ROUND_y'])\n",
    "all_data = all_data.rename(columns={'YEAR_x': 'YEAR', 'TEAM_x': 'TEAM', 'SEED_x': 'SEED', 'ROUND_x': 'ROUND', 'CONF_x': 'CONF', 'TEAM ID_x': 'TEAM ID'})\n",
    "\n",
    "# Drops any more columns that don't seem useful\n",
    "all_data = all_data.drop(columns=['CONF ID', 'QUAD NO', 'TEAM ID', 'TARGET', 'VAL Z-SCORE', 'ROUND', 'TEAM ID_y', 'CONF_y'])\n",
    "\n",
    "all_data['new_seeding_code'] = all_data['SEED'].astype(str) + all_data['QUAD ID'].astype(str)\n",
    "\n",
    "mapping = {\n",
    "    '14': 1,   '11': 2,   '12': 3,   '13': 4,\n",
    "    '23': 5,   '22': 6,   '21': 7,   '24': 8,\n",
    "    '34': 9,   '31': 10,  '32': 11,  '33': 12,\n",
    "    '43': 13,  '42': 14,  '41': 15,  '44': 16,\n",
    "    '54': 17,  '51': 18,  '52': 19,  '53': 20,\n",
    "    '63': 21,  '62': 22,  '61': 23,  '64': 24,\n",
    "    '74': 25,  '71': 26,  '72': 27,  '73': 28,\n",
    "    '83': 29,  '82': 30,  '81': 31,  '84': 32,\n",
    "    '94': 33,  '91': 34,  '92': 35,  '93': 36,\n",
    "    '103': 37, '102': 38, '101': 39, '104': 40,\n",
    "    '114': 41, '111': 42, '112': 43, '113': 44,\n",
    "    '123': 45, '122': 46, '121': 47, '124': 48,\n",
    "    '134': 49, '131': 50, '132': 51, '133': 52,\n",
    "    '143': 53, '142': 54, '141': 55, '144': 56,\n",
    "    '154': 57, '151': 58, '152': 59, '153': 60,\n",
    "    '163': 61, '162': 62, '161': 63, '164': 64\n",
    "}\n",
    "\n",
    "all_data['SEED'] = all_data['new_seeding_code'].map(mapping)\n",
    "\n",
    "all_data = all_data.drop(columns=['new_seeding_code'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are coach and conference results that seem cool and would be interesting, but scare me because of potential data leakage. For example, Bill Self won a championship a few years ago, but before that his championships would be at zero... So I don't think it's a good idea to include it. Conference results are similar, but might be more watered down because they're average over the entire conference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153\n"
     ]
    }
   ],
   "source": [
    "# Prints the number of columns\n",
    "print(len(all_data.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our feature space is really high, so we're going to try and reduce it by removing the columns that rank the features. These are obviously highly correlated with the features themselves, we're just losing some information about how the team compared to other teams in its season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.drop(columns=[col for col in all_data.columns if 'RANK' in col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n"
     ]
    }
   ],
   "source": [
    "# Prints the number of columns\n",
    "print(len(all_data.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now we're down to a more reasonable space. I'm sure there's some unimportant features, or features with high collinearity that we can weed out, but we'll have to more to find them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv(\"All_Data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>CONF</th>\n",
       "      <th>QUAD ID</th>\n",
       "      <th>TEAM NO</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>SEED</th>\n",
       "      <th>K TEMPO</th>\n",
       "      <th>KADJ T</th>\n",
       "      <th>K OFF</th>\n",
       "      <th>KADJ O</th>\n",
       "      <th>...</th>\n",
       "      <th>CLOSE TWOS FG%D</th>\n",
       "      <th>CLOSE TWOS D SHARE</th>\n",
       "      <th>FARTHER TWOS FG%</th>\n",
       "      <th>FARTHER TWOS SHARE</th>\n",
       "      <th>FARTHER TWOS FG%D</th>\n",
       "      <th>FARTHER TWOS D SHARE</th>\n",
       "      <th>THREES FG%</th>\n",
       "      <th>THREES SHARE</th>\n",
       "      <th>THREES FG%D</th>\n",
       "      <th>THREES D SHARE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>MAC</td>\n",
       "      <td>1</td>\n",
       "      <td>1079</td>\n",
       "      <td>Akron</td>\n",
       "      <td>55.0</td>\n",
       "      <td>66.7747</td>\n",
       "      <td>65.8933</td>\n",
       "      <td>107.841</td>\n",
       "      <td>107.0090</td>\n",
       "      <td>...</td>\n",
       "      <td>58.0</td>\n",
       "      <td>37.7</td>\n",
       "      <td>43.8</td>\n",
       "      <td>24.6</td>\n",
       "      <td>39.9</td>\n",
       "      <td>25.6</td>\n",
       "      <td>32.0</td>\n",
       "      <td>41.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>36.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>SEC</td>\n",
       "      <td>3</td>\n",
       "      <td>1078</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>13.0</td>\n",
       "      <td>74.1625</td>\n",
       "      <td>72.6461</td>\n",
       "      <td>121.712</td>\n",
       "      <td>125.6010</td>\n",
       "      <td>...</td>\n",
       "      <td>60.2</td>\n",
       "      <td>37.9</td>\n",
       "      <td>35.7</td>\n",
       "      <td>10.8</td>\n",
       "      <td>37.6</td>\n",
       "      <td>25.3</td>\n",
       "      <td>36.5</td>\n",
       "      <td>46.8</td>\n",
       "      <td>31.9</td>\n",
       "      <td>36.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>P12</td>\n",
       "      <td>3</td>\n",
       "      <td>1077</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>5.0</td>\n",
       "      <td>73.3760</td>\n",
       "      <td>71.8379</td>\n",
       "      <td>117.653</td>\n",
       "      <td>121.1250</td>\n",
       "      <td>...</td>\n",
       "      <td>57.4</td>\n",
       "      <td>30.3</td>\n",
       "      <td>37.9</td>\n",
       "      <td>23.1</td>\n",
       "      <td>38.5</td>\n",
       "      <td>31.5</td>\n",
       "      <td>37.1</td>\n",
       "      <td>32.6</td>\n",
       "      <td>33.4</td>\n",
       "      <td>38.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>SEC</td>\n",
       "      <td>4</td>\n",
       "      <td>1076</td>\n",
       "      <td>Auburn</td>\n",
       "      <td>16.0</td>\n",
       "      <td>70.9629</td>\n",
       "      <td>69.7887</td>\n",
       "      <td>117.364</td>\n",
       "      <td>120.5790</td>\n",
       "      <td>...</td>\n",
       "      <td>48.3</td>\n",
       "      <td>42.0</td>\n",
       "      <td>41.6</td>\n",
       "      <td>21.1</td>\n",
       "      <td>33.6</td>\n",
       "      <td>24.7</td>\n",
       "      <td>35.2</td>\n",
       "      <td>37.5</td>\n",
       "      <td>29.8</td>\n",
       "      <td>33.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>B12</td>\n",
       "      <td>3</td>\n",
       "      <td>1075</td>\n",
       "      <td>Baylor</td>\n",
       "      <td>12.0</td>\n",
       "      <td>66.8428</td>\n",
       "      <td>65.6032</td>\n",
       "      <td>117.262</td>\n",
       "      <td>122.4900</td>\n",
       "      <td>...</td>\n",
       "      <td>65.7</td>\n",
       "      <td>29.8</td>\n",
       "      <td>37.5</td>\n",
       "      <td>26.9</td>\n",
       "      <td>40.0</td>\n",
       "      <td>34.6</td>\n",
       "      <td>39.4</td>\n",
       "      <td>38.3</td>\n",
       "      <td>33.5</td>\n",
       "      <td>35.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>2008</td>\n",
       "      <td>BE</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>26.0</td>\n",
       "      <td>66.2223</td>\n",
       "      <td>63.0942</td>\n",
       "      <td>111.246</td>\n",
       "      <td>113.5700</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>2008</td>\n",
       "      <td>SB</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Western Kentucky</td>\n",
       "      <td>47.0</td>\n",
       "      <td>68.7887</td>\n",
       "      <td>66.5432</td>\n",
       "      <td>110.914</td>\n",
       "      <td>111.0760</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>2008</td>\n",
       "      <td>BSth</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Winthrop</td>\n",
       "      <td>49.0</td>\n",
       "      <td>63.7666</td>\n",
       "      <td>60.9746</td>\n",
       "      <td>101.646</td>\n",
       "      <td>99.6932</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>2008</td>\n",
       "      <td>B10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>12.0</td>\n",
       "      <td>62.1920</td>\n",
       "      <td>60.8809</td>\n",
       "      <td>108.495</td>\n",
       "      <td>113.6190</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>2008</td>\n",
       "      <td>A10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Xavier</td>\n",
       "      <td>10.0</td>\n",
       "      <td>65.1599</td>\n",
       "      <td>62.8978</td>\n",
       "      <td>115.214</td>\n",
       "      <td>116.4130</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1079 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      YEAR  CONF  QUAD ID  TEAM NO              TEAM  SEED  K TEMPO   KADJ T  \\\n",
       "0     2024   MAC        1     1079             Akron  55.0  66.7747  65.8933   \n",
       "1     2024   SEC        3     1078           Alabama  13.0  74.1625  72.6461   \n",
       "2     2024   P12        3     1077           Arizona   5.0  73.3760  71.8379   \n",
       "3     2024   SEC        4     1076            Auburn  16.0  70.9629  69.7887   \n",
       "4     2024   B12        3     1075            Baylor  12.0  66.8428  65.6032   \n",
       "...    ...   ...      ...      ...               ...   ...      ...      ...   \n",
       "1074  2008    BE        1        5     West Virginia  26.0  66.2223  63.0942   \n",
       "1075  2008    SB        1        4  Western Kentucky  47.0  68.7887  66.5432   \n",
       "1076  2008  BSth        4        3          Winthrop  49.0  63.7666  60.9746   \n",
       "1077  2008   B10        3        2         Wisconsin  12.0  62.1920  60.8809   \n",
       "1078  2008   A10        1        1            Xavier  10.0  65.1599  62.8978   \n",
       "\n",
       "        K OFF    KADJ O  ...  CLOSE TWOS FG%D  CLOSE TWOS D SHARE  \\\n",
       "0     107.841  107.0090  ...             58.0                37.7   \n",
       "1     121.712  125.6010  ...             60.2                37.9   \n",
       "2     117.653  121.1250  ...             57.4                30.3   \n",
       "3     117.364  120.5790  ...             48.3                42.0   \n",
       "4     117.262  122.4900  ...             65.7                29.8   \n",
       "...       ...       ...  ...              ...                 ...   \n",
       "1074  111.246  113.5700  ...              NaN                 NaN   \n",
       "1075  110.914  111.0760  ...              NaN                 NaN   \n",
       "1076  101.646   99.6932  ...              NaN                 NaN   \n",
       "1077  108.495  113.6190  ...              NaN                 NaN   \n",
       "1078  115.214  116.4130  ...              NaN                 NaN   \n",
       "\n",
       "      FARTHER TWOS FG%  FARTHER TWOS SHARE  FARTHER TWOS FG%D  \\\n",
       "0                 43.8                24.6               39.9   \n",
       "1                 35.7                10.8               37.6   \n",
       "2                 37.9                23.1               38.5   \n",
       "3                 41.6                21.1               33.6   \n",
       "4                 37.5                26.9               40.0   \n",
       "...                ...                 ...                ...   \n",
       "1074               NaN                 NaN                NaN   \n",
       "1075               NaN                 NaN                NaN   \n",
       "1076               NaN                 NaN                NaN   \n",
       "1077               NaN                 NaN                NaN   \n",
       "1078               NaN                 NaN                NaN   \n",
       "\n",
       "      FARTHER TWOS D SHARE  THREES FG%  THREES SHARE  THREES FG%D  \\\n",
       "0                     25.6        32.0          41.5         30.0   \n",
       "1                     25.3        36.5          46.8         31.9   \n",
       "2                     31.5        37.1          32.6         33.4   \n",
       "3                     24.7        35.2          37.5         29.8   \n",
       "4                     34.6        39.4          38.3         33.5   \n",
       "...                    ...         ...           ...          ...   \n",
       "1074                   NaN         NaN           NaN          NaN   \n",
       "1075                   NaN         NaN           NaN          NaN   \n",
       "1076                   NaN         NaN           NaN          NaN   \n",
       "1077                   NaN         NaN           NaN          NaN   \n",
       "1078                   NaN         NaN           NaN          NaN   \n",
       "\n",
       "      THREES D SHARE  \n",
       "0               36.8  \n",
       "1               36.7  \n",
       "2               38.2  \n",
       "3               33.3  \n",
       "4               35.5  \n",
       "...              ...  \n",
       "1074             NaN  \n",
       "1075             NaN  \n",
       "1076             NaN  \n",
       "1077             NaN  \n",
       "1078             NaN  \n",
       "\n",
       "[1079 rows x 89 columns]"
      ]
     },
     "execution_count": 645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "quadrants = kenpom_barttorvik[['TEAM NO', 'QUAD ID']]\n",
    "\n",
    "tournament_matchups = tournament_matchups.merge(\n",
    "    quadrants, how='left', on='TEAM NO', suffixes=('', '_drop')\n",
    ").drop(columns=['QUAD ID_drop'], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_to_remove = [2034, 2033, 2028, 2027, 1980, 1979, 1976, 1975]\n",
    "tournament_matchups = tournament_matchups[~tournament_matchups['BY YEAR NO'].isin(ids_to_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>ROUND</th>\n",
       "      <th>CONF_1</th>\n",
       "      <th>TEAM_1</th>\n",
       "      <th>SEED_1</th>\n",
       "      <th>SEED_2</th>\n",
       "      <th>CONF_2</th>\n",
       "      <th>TEAM_2</th>\n",
       "      <th>SCORE_diff</th>\n",
       "      <th>K TEMPO_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>CLOSE TWOS D SHARE_diff</th>\n",
       "      <th>FARTHER TWOS FG%_diff</th>\n",
       "      <th>FARTHER TWOS SHARE_diff</th>\n",
       "      <th>FARTHER TWOS FG%D_diff</th>\n",
       "      <th>FARTHER TWOS D SHARE_diff</th>\n",
       "      <th>THREES FG%_diff</th>\n",
       "      <th>THREES SHARE_diff</th>\n",
       "      <th>THREES FG%D_diff</th>\n",
       "      <th>THREES D SHARE_diff</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>64</td>\n",
       "      <td>BE</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>ASun</td>\n",
       "      <td>Stetson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.397</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-7.9</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>-10.2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>64</td>\n",
       "      <td>ACC</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>4.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NEC</td>\n",
       "      <td>Wagner</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.892</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>-4.9</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>64</td>\n",
       "      <td>B12</td>\n",
       "      <td>Houston</td>\n",
       "      <td>3.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>BSth</td>\n",
       "      <td>Longwood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.734</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-8.6</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.1</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>64</td>\n",
       "      <td>B10</td>\n",
       "      <td>Purdue</td>\n",
       "      <td>2.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>SWAC</td>\n",
       "      <td>Grambling St.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.695</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>5.2</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>64</td>\n",
       "      <td>B12</td>\n",
       "      <td>Iowa St.</td>\n",
       "      <td>8.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Sum</td>\n",
       "      <td>South Dakota St.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>-7.4</td>\n",
       "      <td>13.3</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>-3.7</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "      <td>SEC</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>BE</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>6.214</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-3.7</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "      <td>ACC</td>\n",
       "      <td>Duke</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>B12</td>\n",
       "      <td>Baylor</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.265</td>\n",
       "      <td>...</td>\n",
       "      <td>12.3</td>\n",
       "      <td>-6.6</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-5.4</td>\n",
       "      <td>-9.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>B10</td>\n",
       "      <td>Michigan St.</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Horz</td>\n",
       "      <td>Butler</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.311</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>13.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>-4.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-13.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>BE</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACC</td>\n",
       "      <td>Duke</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>-3.704</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>-7.9</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>Horz</td>\n",
       "      <td>Butler</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACC</td>\n",
       "      <td>Duke</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-3.375</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-13.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>888 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     YEAR  ROUND CONF_1          TEAM_1  SEED_1  SEED_2 CONF_2  \\\n",
       "0    2024     64     BE     Connecticut     1.0    64.0   ASun   \n",
       "1    2024     64    ACC  North Carolina     4.0    61.0    NEC   \n",
       "2    2024     64    B12         Houston     3.0    62.0   BSth   \n",
       "3    2024     64    B10          Purdue     2.0    63.0   SWAC   \n",
       "4    2024     64    B12        Iowa St.     8.0    57.0    Sum   \n",
       "..    ...    ...    ...             ...     ...     ...    ...   \n",
       "883  2010      8    SEC        Kentucky     3.0     6.0     BE   \n",
       "884  2010      8    ACC            Duke     2.0    10.0    B12   \n",
       "885  2010      4    B10    Michigan St.    17.0    20.0   Horz   \n",
       "886  2010      4     BE   West Virginia     6.0     2.0    ACC   \n",
       "887  2010      2   Horz          Butler    20.0     2.0    ACC   \n",
       "\n",
       "               TEAM_2  SCORE_diff  K TEMPO_diff  ...  CLOSE TWOS D SHARE_diff  \\\n",
       "0             Stetson         NaN        -0.397  ...                     -0.4   \n",
       "1              Wagner         NaN         8.892  ...                     -3.7   \n",
       "2            Longwood         NaN        -3.734  ...                      1.2   \n",
       "3       Grambling St.         NaN         2.695  ...                     -6.6   \n",
       "4    South Dakota St.         NaN         0.036  ...                     -3.9   \n",
       "..                ...         ...           ...  ...                      ...   \n",
       "883     West Virginia        -7.0         6.214  ...                     -3.8   \n",
       "884            Baylor         7.0         0.265  ...                     12.3   \n",
       "885            Butler        -2.0         2.311  ...                     -0.5   \n",
       "886              Duke       -21.0        -3.704  ...                      1.0   \n",
       "887              Duke        -2.0        -3.375  ...                     -3.0   \n",
       "\n",
       "     FARTHER TWOS FG%_diff  FARTHER TWOS SHARE_diff  FARTHER TWOS FG%D_diff  \\\n",
       "0                     -7.9                     -6.9                   -10.2   \n",
       "1                      7.7                     -4.9                    -4.6   \n",
       "2                     -3.6                      5.0                    -8.6   \n",
       "3                      1.4                     -2.3                    -3.0   \n",
       "4                     -7.4                     13.3                    -1.4   \n",
       "..                     ...                      ...                     ...   \n",
       "883                    0.1                     -3.7                    -2.6   \n",
       "884                   -6.6                     -0.9                    -3.9   \n",
       "885                    3.5                     13.1                     4.4   \n",
       "886                    3.5                     -2.1                     2.3   \n",
       "887                    5.0                    -13.8                     0.7   \n",
       "\n",
       "     FARTHER TWOS D SHARE_diff  THREES FG%_diff  THREES SHARE_diff  \\\n",
       "0                          4.6              0.2               -0.9   \n",
       "1                          8.8              3.8               -2.3   \n",
       "2                         -2.7              0.3                8.1   \n",
       "3                          2.8              6.7                5.2   \n",
       "4                          6.0             -1.3               -8.2   \n",
       "..                         ...              ...                ...   \n",
       "883                        1.6             -0.5               -3.0   \n",
       "884                       -3.2              0.3                0.6   \n",
       "885                       -4.7              0.2              -13.6   \n",
       "886                       -7.9             -4.6                1.7   \n",
       "887                       -3.5             -4.2                6.9   \n",
       "\n",
       "     THREES FG%D_diff  THREES D SHARE_diff  target  \n",
       "0                -2.6                 -4.2     NaN  \n",
       "1                 1.5                 -5.0     NaN  \n",
       "2                -4.5                  1.6     NaN  \n",
       "3                -2.3                  3.8     NaN  \n",
       "4                -3.7                 -2.1     NaN  \n",
       "..                ...                  ...     ...  \n",
       "883              -1.0                  2.2     0.0  \n",
       "884              -5.4                 -9.1     1.0  \n",
       "885               1.4                  5.3     0.0  \n",
       "886               4.1                  6.9     0.0  \n",
       "887               3.1                  6.4     0.0  \n",
       "\n",
       "[888 rows x 92 columns]"
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd_index_matchups = tournament_matchups.iloc[::2]\n",
    "even_index_matchups = tournament_matchups.iloc[1::2]\n",
    "\n",
    "odd_index_matchups = odd_index_matchups.reset_index(drop=True)\n",
    "odd_index_matchups = odd_index_matchups.merge(all_data, how='left', on='TEAM NO')\n",
    "\n",
    "even_index_matchups = even_index_matchups.reset_index(drop=True)\n",
    "even_index_matchups = even_index_matchups.merge(all_data, how='left', on='TEAM NO')\n",
    "\n",
    "odd_index_matchups.columns = [col + '_1' for col in odd_index_matchups.columns]\n",
    "even_index_matchups.columns = [col + '_2' for col in even_index_matchups.columns]\n",
    "\n",
    "combined_matchups = pd.concat([odd_index_matchups, even_index_matchups], axis=1)\n",
    "columns_to_drop = [\n",
    "    'YEAR_y_1', \n",
    "    'YEAR_x_2', \n",
    "    'YEAR_y_2', \n",
    "    'TEAM_y_1', \n",
    "    'TEAM_y_2', \n",
    "    'BY YEAR NO_1', \n",
    "    'BY YEAR NO_2', \n",
    "    'BY ROUND NO_1', \n",
    "    'BY ROUND NO_2', \n",
    "    'TEAM NO_1', \n",
    "    'TEAM NO_2',\n",
    "    'SEED_x_1',\n",
    "    'SEED_x_2',\n",
    "    'QUAD ID_x_1',\n",
    "    'QUAD ID_x_2',\n",
    "    'QUAD ID_y_1',\n",
    "    'QUAD ID_y_2',\n",
    "    'ROUND_1',\n",
    "    'ROUND_2',\n",
    "    'CURRENT ROUND_2',\n",
    "    'BID TYPE_1',\n",
    "    'BID TYPE_2'\n",
    "]\n",
    "existing_columns_to_drop = [col for col in columns_to_drop if col in combined_matchups.columns]\n",
    "combined_matchups = combined_matchups.drop(columns=existing_columns_to_drop)\n",
    "\n",
    "combined_matchups = combined_matchups.rename(columns={\n",
    "    'YEAR_x_1': 'YEAR',\n",
    "    'TEAM_x_1': 'TEAM_1',\n",
    "    'TEAM_x_2': 'TEAM_2',\n",
    "    'SEED_y_1': 'SEED_1',\n",
    "    'SEED_y_2': 'SEED_2',\n",
    "    'CURRENT ROUND_1': 'ROUND'\n",
    "})\n",
    "\n",
    "desired_order = ['YEAR', 'ROUND', 'CONF_1', 'TEAM_1', 'SEED_1', 'SEED_2', 'CONF_2', 'TEAM_2']\n",
    "remaining_columns = [col for col in combined_matchups.columns if col not in desired_order]\n",
    "combined_matchups = combined_matchups[desired_order + remaining_columns]\n",
    "\n",
    "columns_to_process = [col for col in remaining_columns if '_1' in col]\n",
    "\n",
    "for col_1 in columns_to_process:\n",
    "    col_2 = col_1.replace('_1', '_2')\n",
    "    if col_2 in combined_matchups.columns:\n",
    "        combined_matchups[col_1.replace('_1', '') + '_diff'] = (combined_matchups[col_1].astype(float) - combined_matchups[col_2].astype(float)).round(3)\n",
    "        combined_matchups = combined_matchups.drop(columns=[col_1, col_2])\n",
    "\n",
    "# Filter out 2008 and 2009 since shooting splits aren't available\n",
    "combined_matchups = combined_matchups[combined_matchups['YEAR'] >= 2010]\n",
    "\n",
    "combined_matchups['target'] = np.where(combined_matchups['SCORE_diff'].isnull(), np.nan, \n",
    "                                       np.where(combined_matchups['SCORE_diff'] > 0, 1, 0))\n",
    "\n",
    "combined_matchups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_matchups.to_csv(\"combined_matchups.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
